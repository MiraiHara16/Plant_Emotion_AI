{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤ API URL, USERNAME, PASSWORD ‡∏Ç‡∏≠‡∏á Netpie\n",
    "API_URL = \"https://api.netpie.io/v2/device/shadow/data\"\n",
    "USERNAME = \"Token Device\"\n",
    "PASSWORD = \"Secret Device\"\n",
    "\n",
    "# ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Netpie\n",
    "response = requests.get(API_URL, auth=HTTPBasicAuth(USERNAME, PASSWORD))\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "if response.status_code == 200:\n",
    "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON\n",
    "    data = response.json()\n",
    "\n",
    "    # ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏à‡∏≤‡∏Å API\n",
    "    print(\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏à‡∏≤‡∏Å Netpie:\")\n",
    "    print(data)\n",
    "\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "    message = f\"\"\"\n",
    "    üö® ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏à‡∏≤‡∏Å NetPIE üö®\n",
    "\n",
    "    üå°Ô∏è **‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥**: {data['data'].get('temperature', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')} ¬∞C\n",
    "    üíß **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô**: {data['data'].get('humidity', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')} %\n",
    "    üåä **‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡πâ‡∏≥**: {data['data'].get('water_level', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}\n",
    "    üå± **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô‡πÉ‡∏ô‡∏î‡∏¥‡∏ô**: {data['data'].get('soil_moisture', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}\n",
    "    üåÄ **‡∏Ñ‡πà‡∏≤ MQ Sensor**: {data['data'].get('mq_sensor', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}\n",
    "\n",
    "    üìÖ **‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**: {data.get('timestamp', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')}\n",
    "\n",
    "    ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ NetPIE!\n",
    "    \"\"\"\n",
    "\n",
    "    # ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á LINE\n",
    "    line_api_url = \"https://api.line.me/v2/bot/message/broadcast\"\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer ',  # ‡πÉ‡∏™‡πà Access Token ‡∏Ç‡∏≠‡∏á LINE \n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": message\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # ‡∏™‡πà‡∏á POST Request ‡πÑ‡∏õ‡∏¢‡∏±‡∏á LINE API\n",
    "    line_response = requests.post(line_api_url, headers=headers, json=payload)\n",
    "\n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "    if line_response.status_code == 200:\n",
    "        print(\"‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏¢‡∏±‡∏á LINE ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
    "    else:\n",
    "        print(f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏¢‡∏±‡∏á LINE: {line_response.text}\")\n",
    "else:\n",
    "    print(f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Netpie: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api.netpie.io/v2/feed/api/v1/datapoints/query\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer \", # ‡πÉ‡∏™‡πà Access Token ‡∏Ç‡∏≠‡∏á LINE \n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"start_relative\": {\n",
    "        \"value\": 1,\n",
    "        \"unit\": \"days\"\n",
    "    },\n",
    "    \"metrics\": [\n",
    "        {\n",
    "            \"name\": \"Token Device\",\n",
    "            \"tags\": {\n",
    "                \"attr\": [\"temperature\", \"humidity\", \"water_level\", \"soil_moisture\", \"mq_sensor\"]\n",
    "            },\n",
    "            \"limit\": 50,\n",
    "            \"group_by\": [\n",
    "                {\n",
    "                    \"name\": \"tag\",\n",
    "                    \"tags\": [\"attr\"]\n",
    "                }\n",
    "            ],\n",
    "            \"aggregators\": [\n",
    "                {\n",
    "                    \"name\": \"avg\",\n",
    "                    \"sampling\": {\n",
    "                        \"value\": \"1\",\n",
    "                        \"unit\": \"minutes\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    results = data.get(\"queries\", [{}])[0].get(\"results\", [])\n",
    "\n",
    "    attr_data = {}\n",
    "\n",
    "    for result in results:\n",
    "        attr = result.get(\"tags\", {}).get(\"attr\", [None])[0]\n",
    "        values = result.get(\"values\", [])\n",
    "        if attr and values:\n",
    "            attr_data[attr] = [v[1] for v in values]  # ‡∏î‡∏∂‡∏á‡πÅ‡∏ï‡πà‡∏Ñ‡πà‡∏≤ value\n",
    "\n",
    "    # ‡∏´‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÄ‡∏ß‡∏•‡∏≤ zip\n",
    "    min_len = min(len(v) for v in attr_data.values())\n",
    "\n",
    "    combined_data = []\n",
    "    for i in range(min_len):\n",
    "        entry = {\n",
    "            \"temperature\": attr_data.get(\"temperature\", [None]*min_len)[i],\n",
    "            \"humidity\": attr_data.get(\"humidity\", [None]*min_len)[i],\n",
    "            \"water_level\": attr_data.get(\"water_level\", [None]*min_len)[i],\n",
    "            \"soil_moisture\": attr_data.get(\"soil_moisture\", [None]*min_len)[i],\n",
    "            \"mq_sensor\": attr_data.get(\"mq_sensor\", [None]*min_len)[i],\n",
    "        }\n",
    "        combined_data.append(entry)\n",
    "\n",
    "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÑ‡∏ü‡∏•‡πå\n",
    "    with open(\"/content/data.json\", \"w\") as f:\n",
    "        json.dump(combined_data, f, indent=2)\n",
    "\n",
    "    print(\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà /content/data.json\")\n",
    "else:\n",
    "    print(\"‚ùå Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "\n",
    "# --- NETPIE Auth ---\n",
    "USERNAME = \"Token Device\"\n",
    "PASSWORD = \"Secret Device\"\n",
    "API_URL = \"https://api.netpie.io/v2/device/shadow/data\"\n",
    "\n",
    "# --- Load historical data for training ---\n",
    "def load_training_data():\n",
    "    try:\n",
    "        with open(\"data.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        df[\"growth_rate\"] = (df[\"temperature\"] * 0.5) + (df[\"humidity\"] * 0.3) - (df[\"water_level\"] * 0.2) + (df[\"soil_moisture\"] * 0.1)\n",
    "        return df\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(\"‚ùå Error loading training data:\", e)\n",
    "        return None\n",
    "\n",
    "# --- Fetch data from NETPIE ---\n",
    "def fetch_latest_data():\n",
    "    response = requests.get(API_URL, auth=HTTPBasicAuth(USERNAME, PASSWORD))\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get(\"data\", None)\n",
    "    else:\n",
    "        print(\"‚ùå Error fetching data:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# --- Save latest prediction to separate file ---\n",
    "def save_latest_prediction(latest_record):\n",
    "    try:\n",
    "        with open(\"latest_prediction.json\", \"w\") as f:\n",
    "            json.dump(latest_record, f, indent=4)\n",
    "        print(\"‚úÖ Saved latest prediction to latest_prediction.json\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error saving latest prediction:\", e)\n",
    "\n",
    "# --- Main Workflow ---\n",
    "df = load_training_data()\n",
    "if df is not None:\n",
    "    # Prepare training data\n",
    "    X = df[[\"temperature\", \"humidity\", \"water_level\", \"soil_moisture\"]]\n",
    "    y = df[\"growth_rate\"]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # --- Train Random Forest with GridSearch ---\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    grid_search_rf = GridSearchCV(rf_model, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "    grid_search_rf.fit(X_scaled, y)\n",
    "\n",
    "    best_rf_model = grid_search_rf.best_estimator_\n",
    "    print(\"Best Random Forest Parameters:\", grid_search_rf.best_params_)\n",
    "\n",
    "    # --- Train Neural Network ---\n",
    "    nn_model = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(X_scaled.shape[1],)),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    nn_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    nn_model.fit(X_scaled, y, epochs=200, batch_size=32, verbose=0)\n",
    "\n",
    "    # Fetch latest data and predict\n",
    "    latest_data = fetch_latest_data()\n",
    "    if latest_data:\n",
    "        try:\n",
    "            input_data = np.array([[latest_data[\"temperature\"], latest_data[\"humidity\"],\n",
    "                                    latest_data[\"water_level\"], latest_data[\"soil_moisture\"]]])\n",
    "\n",
    "            # Predict\n",
    "            rf_pred = best_rf_model.predict(scaler.transform(input_data))[0]\n",
    "            nn_pred = nn_model.predict(scaler.transform(input_data))[0][0]\n",
    "\n",
    "            print(\"\\nüìä Real-time Prediction\")\n",
    "            print(f\"üå± Random Forest Growth Rate: {rf_pred:.2f}%\")\n",
    "            print(f\"üåø Neural Network Growth Rate: {nn_pred:.2f}%\")\n",
    "\n",
    "            # Convert float32 to float before saving\n",
    "            latest_data[\"growth_rate_rf\"] = round(float(rf_pred), 2)\n",
    "            latest_data[\"growth_rate_nn\"] = round(float(nn_pred), 2)\n",
    "            latest_data[\"timestamp\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            # Save the latest prediction\n",
    "            save_latest_prediction(latest_data)\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(f\"‚ö†Ô∏è Missing key in latest data: {e}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No data fetched from NETPIE.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Training data unavailable.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
